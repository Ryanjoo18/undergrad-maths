\chapter{Complex Numbers and Functions}\label{chap:complex-functions}
\section{$\CC$ As Metric Space}
We can identify $\CC$ with the plane $\RR^2$ by taking
real and imaginary parts. Thus we have mutually inverse bijections
\[z\mapsto(\Re z,\Im z)\]
from $\CC$ to $\RR^2$, and
\[(x,y)\mapsto x+iy\]
from $\RR^2$ to $\CC$. As we have seen, $\RR^2$ is a metric space with the metric induced from the Euclidean norm
\[\norm{(x,y)}_2=\sqrt{x^2+y^2}.\]
This gives a metric on $\CC$ by the identification $\CC\cong\RR^2$ described above.

If $z=\Re z+i\Im z$ is a complex number we write $|z|$ (called the \vocab{modulus}) for this Euclidean norm; that is,
\[|z|=\sqrt{(\Re z)^2+(\Im z)^2}.\]
The distance between the two points $z,w\in\CC$ is then $|z-w|$.

Let us write down some basic properties of the modulus $|z|$. Recall that $e^{i\theta}=\cos\theta+i\sin\theta$ when $\theta\in\RR$. For now, we will take this as the definition of $e^{i\theta}$. Later on we will define the complex exponential function $e^z$ and link the two concepts.

\begin{lemma}
Let $z,w\in\CC$. Then
\begin{enumerate}[label=(\roman*)]
\item $|z|^2=z\bar{z}$, where $\bar{z}$ is the complex conjugate of $z$;
\item If $z=re^{i\theta}$, where $r\in[0,\infty)$ and $\theta\in\RR$, then $|z|=r$;
\item $|zw| = |z||w|$.
\end{enumerate}
\end{lemma}

\begin{proof} \
\begin{enumerate}[label=(\roman*)]
\item If $z=a+ib$ then $z\bar{z}=(a+ib)(a-ib)=a^2+b^2$.
\item We have $z=r\cos\theta+ir\sin\theta$ and so
\[|z|=\sqrt{r^2\cos^2\theta+r^2\sin^2\theta}=r.\]
\item One can calculate directly, writing $z=a+ib$ and $w=c+id$. Alternatively, write $z=re^{i\theta}$, $w=r^\prime e^{i\alpha}$, and then observe that $zw=rr^\prime e^{i(\theta+\alpha)}$ and use (2).
\end{enumerate}
\end{proof}

\section{Complex Differentiability}
Suppose that $a\in\CC$, and that $U$ is a neighbourhood of $a$. That is, $U$ contains some ball $B_\eta(a)$ for $\eta>0$, but $U$ itself need not be open. Suppose that $f:U\setminus\{a\}\to\CC$ is a function; that is, $f$ is defined on $U$, except not at $a$. Then we say that $\displaystyle\lim_{z\to a}f(z)=L$ if
\[\forall\epsilon>0,\quad\exists\delta>0,\quad 0<|z-a|<\delta\implies|f(z)-L|<\epsilon\]
(and we assume $\delta<\eta$ so that $f$ is defined when $|z-a|<\delta$).

\subsection{Complex Differentiability}
With the relevant notions of limit having been recalled, we can give the definition of (complex) derivative. In fact, it is the same as the definition of real derivative, but with complex numbers in place of reals.

\begin{definition}[Complex differentiability]
Let $a\in\CC$, and suppose that $f:U\to\CC$ is a function, where $U$ is a neighbourhood of $a$. Then we say that $f$ is \vocab{complex differentiable}\index{complex differentiability} at $a$ if the limit
\[\lim_{z\to a}\frac{f(z)-f(a)}{z-a}\]
exists. If the limit exists, we write $f^\prime(a)$ for it and call this the \textbf{derivative} of $f$ at $a$.
\end{definition}

Since we will be talking exclusively about functions on $\CC$, we just use the terms differentiable/derivative and omit the word ``complex''.

\begin{proposition}[Differentiability implies continuity]
If $f$ is differentiable at $z$, then $f$ is continuous at $z$.
\end{proposition}

\begin{proof}
Suppose $f:U\to\CC$ has derivative 
\[f^\prime(z)=\lim_{h\to0}\frac{f(z+h)-f(z)}{h}.\]
Then
\[\lim_{h\to0}\brac{f(z+h)-f(z)}=f^\prime(z)\lim_{h\to0}h=0.\]
\end{proof}

The following lemma collects the basic facts about derivatives. We omit the proof, which is essentially identical to the real case.

\begin{lemma}
Let $a\in\CC$, let $U$ be a neighbourhood of $a$ and let $f,g:U\to\CC$.
\begin{enumerate}[label=(\roman*)]
\item (Sums, products) If $f,g$ are differentiable at $a$, then $f+g$ and $fg$ are differeitnable at $a$, and
\[(f+g)^\prime(a)=f^\prime(a)+g^\prime(a)\]
and
\[(fg)^\prime(a)=f^\prime(a)g(a)+f(a)g^\prime(a).\]
\item (Quotients) If $f,g$ are differentiable at $a$ and $g(a)\neq0$ then $f/g$ is differentiable at $a$ and
\[\brac{\frac{f}{g}}^\prime(a)=\frac{f^\prime(a)g(a)-f(a)g^\prime(a)}{g(a)^2}.\]
\item (Chain rule) If $U$ and $V$ are open subsets of $\CC$ and $f:V\to U$, $g:U\to\CC$, where $f$ is differentiable at $a\in V$ and $g$ is differeitnable at $f(a)\in U$, then $g\circ f$ is differentiable at $a$, with
\[(g\circ f)^\prime(a)=g^\prime(f(a))f^\prime(a).\]
\end{enumerate}
\end{lemma}

Just as in the real case, the basic rules of differentiation stated above allow one to check that polynomial functions are differentiable: using the product rule and induction one sees that $z^n$ has derivative $nz^{n-1}$ for all $n\ge0$ (as a constant obviously has derivative $0$, and $f(z)=z$ has derivative $1$). Then by linearity it follows every polynomial is differentiable.

Just as in the real-variable case, one can formulate complex differentiability in the following form, which is in fact the better form to use in most instances.

\begin{lemma}
Let $a\in\CC$, let $U$ be a neighbourhood of $a$ and let $f:U\to\CC$. Then $f$ is differentiable at $a$, with derivative $f^\prime(a)$, if and only if
\[f(z)=f(a)+f^\prime(a)(z-a)+\epsilon(z)(z-a),\]
where $\epsilon(z)\to0$ as $z\to a$.
\end{lemma}

\begin{proof}
check that this definition is indeed equivalent to (really just a reformulation of) the previous one.
\end{proof}

\begin{definition}[Holomorphic function]
Let $U\subset\CC$ be an open set. If $f:U\to\CC$ is complex differentiable at every $a\in U$, we say that $f$ is \vocab{holomorphic}\index{holomorphic function} on $U$.
\end{definition}

\subsection{Cauchy--Riemann Equations}
A function from $\CC$ to $\CC$ may also be thought of as a function from $\RR^2$ to $\RR^2$, and it is useful to study what differentiability means in this language.

Let $a\in\CC$, and let $U$ be a neighbourhood of $a$. Let $f:U\to\CC$ be a function. We abuse notation and identify $\CC\cong\RR^2$ in the usual way, and identify $a$ with $(a_1,a_2)$ (thus $a=a_1+ia_2$). Then (again with some abuse of notation) we may think of $U$ as an open subset of $\RR^2$ and write $f=(u,v)$, where $u,v:\RR^2\to\RR$ are called the \emph{components} of $f$. Another way to think of this is that
\[f(x+iy)=u(x,y)+iv(x,y).\]

\begin{example}
Consider the function $f(z)=z^2$ (which is holomorphic on all of $\CC$). Since
\[(x+iy)^2=(x^2-y^2)+(2xy)i,\]
the components of $f$ are given by
\begin{align*}
u(x,y)&=x^2-y^2,\\
v(x,y)&=2xy.
\end{align*}
\end{example}

We have the partial derivatives
\[\pdv{u(a)}{x}\coloneqq\lim_{h\to0}\frac{u(a_1+h,a_2)-u(a_1,a_2)}{h}\]
(if the limit exists) and
\[\pdv{u(a)}{y}\coloneqq\lim_{k\to0}\frac{u(a_1,a_2+k)-u(a_1,a_2)}{k},\]
and similarly for $v$. It is important to note that $h, k$ in these limits are real.

An important fact is that if $f$ is differentiable then these partial derivatives do exist, and moreover they are subject to a constraint.

\begin{theorem}[Cauchy--Riemann equations]
Let $a\in\CC$, let $U$ be a neighbourhood of $a$, and let $f:U\to\CC$ be a function which is complex differentiable at $a$. Let $u,v:\RR^2\to\RR$ be the components of $f$. Then the four partial derivatives $\displaystyle\pdv{u}{x}, \pdv{u}{y}, \pdv{v}{x}, \pdv{v}{y}$ exist at $a$. Moreover, we have the Cauchy--Riemann equations
\begin{equation}
\pdv{u}{x}=\pdv{v}{y}\quad\text{and}\quad\pdv{v}{x}=-\pdv{u}{y}
\end{equation}
and $\displaystyle f^\prime(a)=\pdv{u(a)}{x}+i\pdv{v(a)}{x}$.
\end{theorem}

\begin{proof}
We have
\[f(z)=f(a)+f^\prime(a)(z-a)+\epsilon(z)(z-a),\]
where $\epsilon(z)\to0$ as $z\to a$. Identifying $\CC\cong\RR^2$ and writing $a=(a_1,a_2)$, $z=(a_1+h,a_2+k)$, $f=(u,v)$ and $f^\prime(a)=(b_1,b_2)$, this gives
(u(a1 + h, a2 + k), v(a1 + h, a2 + k))
= (u(a1, a2), v(a1, a2)) + (b1, b2) · (h, k) + (ε1(h, k), ε2(h, k)) · (h, k).
The · here means complex multiplication, under the identification of C and
R
2
: thus
(b1, b2) · (h, k) = (b1h − b2k, b1k + b2h)
(because (b1 + ib2)(h + ik) = (b1h − b2k) + i(b2h + b1k)). The functions
ε1(h, k), ε2(h, k) both tend to 0 as k(h, k)k → 0.
Looking at the first component, we have
u(a1 + h, a2 + k) = u(a1, a2) + b1h − b2k + ε1(h, k)h − ε2(h, k)k.
In particular,
u(a1 + h, a2) = u(a1, a2) + b1h + ε1(h, 0)h.

Since $\epsilon_1(h,0)\to0$ as $|h|\to0$, it follows that $\pdv{u(a)}{x}$ exists and equals $b_1$.

Very similar arguments may be used for the other partial derivatives and we see that they all exist, and that
\[∂yu(a) = −b2, ∂xv(a) = b2, ∂yv(a) = b1.\]
Everything stated in the theorem now follows. 
\end{proof}

Assuming for the time being that $u,v$ have continuous partial derivatives of all orders (and in particular the mixed partials are equal), we can show that
\[\Delta u=\pdv[2]{u}{x}+\pdv[2]{u}{y}=0,\quad\Delta v=\pdv[2]{v}{x}+\pdv[2]{v}{y}=0.\]
Such an equation $\Delta u=0$ is called Laplace's equation and its solution is said to be a harmonic function.

Let us pause to give a simple example using the Cauchy-Riemann equations, which shows that complex differentiation is a much more rigid property than one might think at first sight.

\begin{example}
The function $f(z)=\bar{z}$ is not (complex) differentiable anywhere.
\end{example}

\begin{proof}
Let $u,v:\RR^2\to\RR$ be the components of $f$. Then clearly $u(x,y) = x$, $v(x,y)=-y$ and so $\partial_x u=1,\partial_y u=0, \partial_x v=0, \partial_y v=-1$. Thus $\partial_xu$ is never equal to $\partial_yv$, so the Cauchy--Riemann equations are never satisfied.
\end{proof}

$\CC$ is $\RR^2$ with a multiplication. Note that each map $f:\CC\to\CC$ induces a map $f_R:\RR^2\to\RR^2$ (and vice versa).
\begin{example}
Consider $f:\CC\to\CC$, $z\mapsto z^2$.

This is equivalent to $x+iy\mapsto (x+iy)^2=(x^2-y^2)+(2xy)i$.

Thus the mapping is the same as $f_R:\RR^2\to\RR^2$, $(x,y)\mapsto(x^2-y^2,2xy)$.
\end{example}
We want to form a connection between differentiability in $\CC$ and $\RR^2$.
\begin{definition}
A map $f_R:\RR^2\to\RR^2$ is called (totally) differentiable at $\begin{pmatrix}x_0\\ y_0\end{pmatrix}$ if there is a matrix $J\in\RR^{2\times2}$ and a map $\phi:\RR^2\to\RR^2$
\[f_R\brac{\begin{pmatrix}x\\y\end{pmatrix}}=\underbrace{f_R\brac{\begin{pmatrix}x_0\\y_0\end{pmatrix}}+J\brac{\begin{pmatrix}x\\y\end{pmatrix}-\begin{pmatrix}x_0\\ y_0\end{pmatrix}}}_{\text{linear approximation}}+\underbrace{\phi\brac{\begin{pmatrix}x\\ y\end{pmatrix}}}_{\text{error term}}\]
where $\frac{\phi\brac{\begin{pmatrix}x\\ y\end{pmatrix}}}{\norm{\begin{pmatrix}x\\y\end{pmatrix}-\begin{pmatrix}x_0\\ y_0\end{pmatrix}}}\to0$ as $\begin{pmatrix}x\\y\end{pmatrix}\to\begin{pmatrix}x_0\\ y_0\end{pmatrix}$.

$J$ is called the \textbf{Jacobian matrix} of $f_R$ at $\begin{pmatrix}x_0\\y_0\end{pmatrix}\in\RR^2$:
\[J=\begin{pmatrix}
\vdots&\vdots\\
\frac{\partial f_R}{\partial x}&\frac{\partial f_R}{\partial y}\\
\vdots&\vdots
\end{pmatrix}\]
\end{definition}
\begin{example}
Considering the above example, 
\[J=\begin{pmatrix}
2x&-2y\\
2y&2x
\end{pmatrix}.\]
\end{example}



\begin{comment}
\begin{definition}[Derivative]
The \vocab{derivative} of $f(z)$ at $z=a$ is given by the limit
\[f^\prime(a)=\lim_{z\to a}\frac{f(z)-f(a)}{z-a}.\]
\end{definition}

\subsection{Analytic Functions}
The class of \vocab{analytic functions} is formed by the complex functions of a complex variable which possess a derivative wherever the function is defined.

The definition of the derivative can be rewritten in the form
\[f^\prime(z)=\lim_{h\to0}\frac{f(z+h)-f(z)}{h}.\]
\begin{lemma}[Differentiability implies continuity]
$f(z)$ is continuous if it is analytic.
\end{lemma}

\begin{proof}
From $\displaystyle f(z+h)-f(z)=h\cdot\frac{f(z+h)-f(z)}{h}$ we obtain
\[\lim_{h\to0}\sqbrac{f(z+h)-f(z)}=0\cdot f^\prime(z)=0.\]
\end{proof}

If we write $f(z)=u(z)+iv(z)$ it follows that $u(z)$ and $v(z)$ are both continuous.

The limit of the difference quotient must be the same regardless of the way in which $h$ approaches zero. If we choose real values for $h$, then the imaginary part $y$ is kept constant, and the derivative becomes a partial derivative with respect to $x$. We have thus
\[f^\prime(z)=\pdv{f}{x}=\pdv{u}{x}+i\pdv{v}{x}.\]
Similarly, if we substitute purely imaginary values $ik$ for $h$, we obtain 
\[f^\prime(z)=\lim_{k\to0}\frac{f(z+ik)-f(z)}{ik}=-i\pdv{f}{y}=-i\pdv{u}{y}+\pdv{v}{y}.\]
It follows that $f(z)$ must satisfy the partial differential equation
\[\pdv{f}{x}=-i\pdv{f}{y}\]
which resolves into the real equations
\begin{equation}\label{eqn:cauchy-riemann}
\pdv{u}{x}=\pdv{v}{y},\quad\pdv{u}{y}=-\pdv{v}{x}.
\end{equation}
These are the \vocab{Cauchy--Riemann equations} which must be satisfied by the real and imaginary part of any analytic function.

Using \cref{eqn:cauchy-riemann}, we can write down four formally different expressions for $f^\prime(z)$; the simplest is
\[f^\prime(z)=\pdv{u}{x}+i\pdv{v}{x}.\]
For the quantity $|f^\prime(z)|^2$, we have, for instance,
\[\absolute{f^\prime(z)}^2=\brac{\pdv{u}{x}}^2+\brac{\pdv{u}{y}}^2=\brac{\pdv{u}{x}}^2+\brac{\pdv{v}{x}}^2=\pdv{u}{x}\pdv{v}{y}-\pdv{u}{y}\pdv{v}{x}.\]
The last expression shows that $\absolute{f^\prime(z)}^2$ is the Jacobian of $u$ and $v$ with respect to $x$ and $y$.

We shall prove later that the derivative of an analytic function is itself analytic. By this fact $u$ and $v$ will have continuous partial derivatives of all orders, and in particular the mixed derivatives will be equal. Using this information we obtain from \cref{eqn:cauchy-riemann},
\begin{align*}
\Delta u&=\pdv[2]{u}{x}+\pdv[2]{u}{y}=0,\\
\Delta v&=\pdv[2]{v}{x}+\pdv[2]{v}{y}=0.
\end{align*}
A function $u$ which satisfies \textbf{Laplace's equation} $\Delta u=0$ is said to be \vocab{harmonic}. The real and imaginary part of an analytic function are thus harmonic. If two harmonic functions $u$ and $v$ satisfy the Cauchy--Riemann equations, then $v$ is said to be the \textbf{conjugate harmonic function} of $u$.










\end{comment}
