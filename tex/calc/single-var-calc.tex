\chapter{Single Variable Calculus}
\section{Integration Techniques}
We review the following basic techniques for evaluating integrals:
\begin{itemize}
\item Integration by substitution
\item Integration by parts, reduction formula
\end{itemize}

\subsection{Integration by Substitution}
\begin{exercise}
Evaluate
\[I=\int_{0}^{1}\frac{1}{\sqrt{4-2x-x^2}}\dd{x}.\]
\end{exercise}

\begin{solution}
The integral is close to the known integral $\int\frac{1}{\sqrt{1-x^2}}\dd{x}$. By completing the square we may write
\begin{align*}
4-2x-x^2&=5-(x+1)^2\\
&=5\brac{1-\brac{\frac{x+1}{\sqrt{5}}}^2}.
\end{align*}
Making the substitution $u=\frac{x+1}{\sqrt{5}}$ we have $\dd{u}=\frac{1}{\sqrt{5}}\dd{x}$, so that
\begin{align*}
I&=\int_{0}^{1}\frac{1}{\sqrt{4-2x-x^2}}\dd{x}\\
&=\frac{1}{\sqrt{5}}\int_{0}^{1}\frac{1}{\sqrt{1-\brac{\frac{x+1}{\sqrt{5}}}^2}}\dd{x}\\
&=\frac{1}{\sqrt{5}}\int_{\frac{1}{\sqrt{5}}}^{\frac{2}{\sqrt{5}}}\frac{\sqrt{5}}{\sqrt{1-u^2}}\dd{u}\\
&=\int_{\frac{1}{\sqrt{5}}}^{\frac{2}{\sqrt{5}}}\frac{1}{\sqrt{1-u^2}}\dd{u}\\
&=\sin^{-1}\frac{2}{\sqrt{5}}-\sin^{-1}\frac{1}{\sqrt{5}}.
\end{align*}
\end{solution}

\subsection{Integration by Parts}
Now let us recall the technique of integration by parts. This is the integral form of the product rule for derivatives, that is $(fg)^\prime=f^\prime g+fg^\prime$, where $f$ and $g$ are functions of $x$, and the prime denotes the derivative with respect to $x$. Thus we have
\[f(x)g(x)=\int g(x)f^\prime(x)\dd{x}+\int f(x)g^\prime(x)\dd{x}\]
and we arrange the terms to obtain
\[\int f(x)g^\prime(x)\dd{x}=f(x)g(x)-\int g(x)f^\prime(x)\dd{x}.\]
Similarly, for definite integrals we have
\[\int_{a}^{b}f(x)g^\prime(x)\dd{x}=\sqbrac{f(x)g(x)}_a^b-\int_{a}^{b}g(x)f^\prime(x)\dd{x}.\]

\begin{exercise}
Evaluate
\[I=\int xe^x\dd{x}.\]
\end{exercise}

\begin{solution}
We have $f(x)=x$ and $g^\prime(x)=e^x$, so that $f^\prime(x)=1$ and $g(x)=e^x$. Thus
\begin{align*}
I&=\int xe^x\dd{x}\\
&=xe^x-\int e^x\dd{x}\\
&=xe^x-e^x+c.
\end{align*}
\end{solution}

Sometimes, after two applications of the ``by parts'' formula, we almost get back to where we started:

\begin{exercise}
Evaluate
\[I=\int e^x\sin x\dd{x}.\]
\end{exercise}

\begin{solution}
\begin{align*}
\int e^x\sin x\dd{x}
&=e^x\sin x-\int e^x\cos x\dd{x}\\
&=e^x\sin x-e^x\cos x-\int e^x\sin x\dd{x}.
\end{align*}
Now we see that we have returned to our original integral, so that we can rearrange this equation to obtain
\[\int e^x\sin x\dd{x}=\frac{1}{2}e^x\brac{\sin x-\cos x}+c.\]
\end{solution}

Finally in this section we look at an example of a \emph{reduction formula}.

\begin{exercise}
Consider $I_n=\int\cos^n x\dd{x}$ where $n$ is a non-negative integer. Find a reduction formula for $I_n$, and use this formula to evaluate $\int\cos^7x\dd{x}$.
\end{exercise}

\begin{solution}
The aim here is to write $I_n$ in terms of other $I_k$ where $k<n$, so that eventually we are reduced to calculating $I_0$ or $I_1$, say, both of which are easily found (analagous to a recurrence relation). Using integration by parts we have:
\begin{align*}
I_n&=\int\cos^n x\dd{x}\\
&=\int\cos^{n-1}\times\cos x\dd{x}\\
&=\cos^{n-1}x\sin x+(n-1)\int\cos^{n-2}x\sin^2 x\dd{x}\\
&=\cos^{n-1}x\sin x+(n-1)\int\cos^{n-2}x(1-\cos^2 x)\dd{x}\\
&=\cos^{n-1}x\sin x+(n-1)\brac{I_{n-2}-I_n}.
\end{align*}

Rearranging this to make $I_n$ the subject we obtain
\[I_n=\frac{1}{n}\cos^{n-1}x\sin x+\frac{n-1}{n}I_{n-2}.\]

With this reduction formula, $I_n$ can be rewritten in terms of simpler and simpler integrals until we are left only needing to calculate $I_0$ if $n$ is even, or $I_1$ if $n$ is odd. Therefore, $I_7$ can be found as follows:
\begin{align*}
I_7&=\frac{1}{7}\cos^6x\sin x+\frac{6}{7}I_5\\
&=\frac{1}{7}\cos^6x\sin x+\frac{6}{7}\brac{\frac{1}{5}\cos^4x\sin x+\frac{4}{5}I_3}\\
&=\frac{1}{7}\cos^6x\sin x+\frac{6}{7}\brac{\frac{1}{5}\cos^4x\sin x+\frac{4}{5}\brac{\frac{1}{3}\cos^2x\sin x+\frac{2}{3}I_1}}\\
&=\frac{1}{7}\cos^6x\sin x+\frac{6}{35}\cos^4x\sin x+\frac{24}{105}\cos^2x\sin x+\frac{48}{105}\sin x+c.
\end{align*}
\end{solution}

\section{First Order Differential Equations}
An \vocab{ordinary differential equation} (ODE) is an equation relating a variable, say $x$, a function, say $y$, of the variable $x$, and finitely many of the derivatives of $y$ with respect to $x$. That is, an ODE can be written in the form
\[f\brac{x,y,\dv{y}{x},\dv[2]{y}{x},\dots,\dv[k]{y}{x}}=0\]
for some function $f$, $k\in\NN$. Here $x$ is the independent variable and the ODE governs how the dependent variable $y$ varies with $x$. The equation may have no, one or many functions $y(x)$ which satisfy it; the problem is usually to find the most general solution $y(x)$, a function which satisfies the differential equation.

We say that an ODE has \emph{order} $k$ if it involves derivatives of order $k$ and less. Thus first order differential equations take the form
\[\dv{y}{x}=f(x,y).\]
In general, a $k$-th order ODE takes the form
\[a_k(x)\dv[k]{y}{x}+a_{k-1}(x)\dv[k-1]{y}{x}+\cdots+a_1(x)\dv{y}{x}+a_0(x)y=f(x),\]
where $a_k(x)\neq0$. The ODE is \emph{homogeneous} if $f(x)=0$ for all $x$, and \emph{inhomogeneous} otherwise. 

The following are some standard methods for solving first order ODEs:
\begin{itemize}
\item Direct integration
\item Separation of variables
\item Reduction to separable form by substitution
\item Exact differential equations
\item Integrating factors
\end{itemize}

\subsection{Direct Integration}
If the ODE takes the form
\[\dv{y}{x}=f(x),\]
then we can solve this by direct integration:

\begin{exercise}
Find the general solution to
\[\dv{y}{x}=x^2\sin x.\]
\end{exercise}

\begin{solution}
Integrating both sides with respect to $x$ and then integrating the RHS by parts, we have
\[y=-x^2\cos x+2x\sin x+2\cos x+c.\]
\end{solution}

\subsection{Separation of Variables}
When the ODE is \emph{separable}, that is, it takes the form
\[\dv{y}{x}=a(x)b(y),\]
where $a(x)$ and $b(y)$ are functions of $x$ and $y$ respectively, we can solve this by separating the variables:
\[\frac{1}{b(y)}\dv{y}{x}=a(x),\]
then integrating both sides with respect to $x$ we find
\[\int\frac{1}{b(y)}\dd{y}=\int a(x)\dd{x}.\]
Here we have assumed that $b(y)\neq0$; if $b(y)=0$ then the solution is $y=c$ for some constant $c$.

Some first order differential equations can be transformed by a suitable substitution into separable form.

\begin{exercise}
Find the general solution to
\[\dv{y}{x}=\sin(x+y+1).\]
\end{exercise}

\begin{solution}
Let $u=x+y+1$, so that $\dv{u}{x}=1+\dv{y}{x}$. Then the original equation can be written as
\[\dv{u}{x}=1+\sin u,\]
which is separable. We have 
\[\frac{1}{1+\sin u}\dv{u}{x}=1,\]
which integrates to
\[\int\frac{1}{1+\sin u}\dd{u}=x+c.\]
Let us evaluate the integral on the LHS:
\begin{align*}
\int\frac{1}{1+\sin u}\dd{u}&=\int\frac{1-\sin u}{(1+\sin u)(1-\sin u)}\dd{u}\\
&=\int\frac{1-\sin u}{1-\sin^2 u}\dd{u}\\
&=\int\frac{1-\sin u}{\cos^2 u}\dd{u}\\
&=\int\sec^2 u\dd{u}-\int\sec u\tan u\dd{u}\\
&=\tan u-\sec u+c.
\end{align*}
Therefore the general solution is
\[\tan(x+y+1)-\sec(x+y+1)=x+c.\]
This solution, where we have not found $y$ in terms of $x$, is called an \emph{implicit solution}.
\end{solution}

A special group of first order differential equations are homogeneous ones, of the form
\[\dv{y}{x}=f\brac{\frac{y}{x}}.\]
These can be solved by the substitution of the form $y(x)=xv(x)$, so that the ODE becomes
\[x\dv{v}{x}=f(v)-v,\]
which is separable.

\subsection{Integrating Factor}
Now we look specifically at first order linear ODEs, which take the general form
\[\dv{y}{x}+p(x)y=q(x).\]
We see that the homogeneous form, that is when $q(x)=0$, is separable. The inhomogeneous form can be solved by multiplying an \emph{integrating factor} $I(x)$ given by
\[I(x)=e^{\int p(x)\dd{x}}\]
on both sides of the equation, so that
\[e^{\int p(x)\dd{x}}\dv{y}{x}+p(x)e^{\int p(x)\dd{x}}y=e^{\int p(x)\dd{x}}q(x).\]
Using the product rule for derivatives, this gives
\[\dv{}{x}\brac{e^{\int p(x)\dd{x}}y}=e^{\int p(x)\dd{x}}q(x),\]
which we can integrate directly to find $y(x)$:
\[y(x)=e^{-\int p(x)\dd{x}}\brac{\int e^{\int p(x)\dd{x}}q(x)\dd{x}+c}.\]

\begin{exercise}
Solve the linear differential equation
\[\dv{y}{x}+2xy=2xe^{-x^2}.\]
\end{exercise}

\begin{solution}
The integrating factor is $I(x)=e^{\int 2x\dd{x}}=e^{x^2}$. Multiplying through by this factor gives
\[e^{x^2}\dv{y}{x}+2xe^{x^2}y=2x,\]
that is
\[\dv{}{x}\brac{e^{x^2}y}=2x.\]
Integrating both sides with respect to $x$ we find
\[e^{x^2}y=x^2+c,\]
so that the general solution is
\[y=\brac{x^2+c}e^{-x^2}.\]
\end{solution}

\section{Second Order Linear Differential Equations}
\subsection{Two Theorems}
The main subject of this section is linear ODEs with constant coefficients, but before we look at these we give two theorems that are valid in the more general case.

Recall that a homogeneous linear ODE of order $k$ takes the form
\[a_k(x)\dv[k]{y}{x}+a_{k-1}(x)\dv[k-1]{y}{x}+\cdots+a_1(x)\dv{y}{x}+a_0y=0.\]
It turns out that the space of solutions to this ODE has some nice algebraic properties.

\begin{theorem}
The space of solutions of a homogeneous linear ODE is a real vector space; that is, if $y_1$ and $y_2$ are solutions, then $\alpha_1y_1+\alpha_2y_2$ is also a solution, for $\alpha_1,\alpha_2\in\RR$.
\end{theorem}

\begin{proof}
Suppose
\begin{equation*}\tag{1}
a_k(x)\dv[k]{y_1}{x}+a_{k-1}(x)\dv[k-1]{y_1}{x}+\cdots+a_1(x)\dv{y_1}{x}+a_0(x)y_1=0,
\end{equation*}
\begin{equation*}\tag{2}
a_k(x)\dv[k]{y_2}{x}+a_{k-1}(x)\dv[k-1]{y_2}{x}+\cdots+a_1(x)\dv{y_2}{x}+a_0(x)y_2=0.
\end{equation*}
$\alpha_1\times(1)+\alpha_2\times(2)$ gives
\[a_k(x)\dv[k]{(\alpha_1y_1+\alpha_2y_2)}{x}+a_{k-1}(x)\dv[k-1]{(\alpha_1y_1+\alpha_2y_2)}{x}+\cdots+a_1(x)\dv{(\alpha_1y_1+\alpha_2y_2)}{x}+a_0(x)(\alpha_1y_1+\alpha_2y_2)=0,\]
which shows that $\alpha_1y_1+\alpha_2y_2$ is also a solution to the ODE.
\end{proof}

\begin{remark}
The above holds simply due to differentiation being a linear map.
\end{remark}

In the case where the ODE is linear but inhomogeneous, solving the inhomogeneous equation still strongly relates to the solution of the associated homogeneous equation.

\begin{theorem}\label{thrm:linear-inhomogeneous-ode}
Let $y_p(x)$ be a solution (known as a \emph{particular integral}) of the homogeneous ODE
\[a_k(x)\dv[k]{y}{x}+a_{k-1}(x)\dv[k-1]{y}{x}+\cdots+a_1(x)\dv{y}{x}+a_0(x)y=f(x).\]
Then $y(x)$ is a solution if and only if $y(x)$ can be written as
\[y(x)=y_c(x)+y_p(x),\]
where $y_c(x)$ is a solution of the corresponding homogeneous linear ODE (known as the \emph{complementary function}).
\end{theorem}

\begin{proof}
If $y(x)=y_c(x)+y_p(x)$ is a solution, then
\[a_k(x)\dv[k]{(y_c+y_p)}{x}+a_{k-1}(x)\dv[k-1]{(y_c+y_p)}{x}+\cdots+a_1(x)\dv{(y_c+y_p)}{x}+a_0(x)(y_c+y_p)=f(x).\]
Rearranging brackets,
\[\brac{a_k(x)\dv[k]{y_c}{x}+\cdots+a_0(x)y_c}+\brac{a_k(x)\dv[k]{y_p}{x}+\cdots+a_0(x)y_p}=f(x),\]
where the second bracket equals $f(x)$, since $y_p(x)$ is a solution. Hence the first bracket must equal zero, that is $y_c(x)$ is a solution of the corresponding homogeneous ODE.
\end{proof}

\subsection{Second order homogeneous linear ODEs}
We introduce a method for finding a second solution to a second order homogeneous linear ODE, when one solution has already been found.

Suppose $z(x)\neq0$ is a non-trivial solution to
\begin{equation*}\tag{$\ast$}
p(x)\dv[2]{y}{x}+q(x)\dv{y}{x}+r(x)y=0.
\end{equation*}
Make the substitution $y(x)=u(x)z(x)$ so that $(\ast)$ becomes
\[p(x)\brac{\dv[2]{u}{x}z+2\dv{u}{x}\dv{z}{x}+u\dv[2]{z}{x}}+q(x)\brac{\dv{u}{x}z+u\dv{z}{x}}+r(x)uz=0.\]
Rearranging and using the fact that $z$ is a solution,
\[p(x)z\dv[2]{u}{x}+\brac{2p(x)\dv{z}{x}+q(x)z}\dv{u}{x}=0,\]
which is a homogenous differential equation of first order for $\dv{u}{x}$. In theory this can be solved, to obtain the general solution to ($\ast$). The following example illustrates this technique.

\begin{exercise}
Verify that $z(x)=\frac{1}{x}$ is a solution to
\[x\dv[2]{y}{x}+2(1-x)\dv{y}{x}-2y=0,\]
and hence find its general solution.
\end{exercise}

\begin{solution}
You can easily verify that $z(x)=\frac{1}{x}$ is a solution by direct substitution.

Substituting $y(x)=\frac{1}{x}u(x)$ gives
\[x\frac{1}{x}\dv[2]{u}{x}+\brac{-2x^{-2}x+2(1-x)\frac{1}{x}}\dv{u}{x}=0.\]
Let $w=\dv{u}{x}$, then
\[\dv{w}{x}-2w=0,\]
which is separable and has general solution $w(x)=C_1e^{2x}$. Thus
\[u(x)=\int w(x)\dd{x}=C_1e^{2x}+C_2,\]
so
\[y(x)=\frac{1}{x}\brac{C_1e^{2x}+C_2}.\]
\end{solution}

\subsection{Linear ODEs with constant coefficients}
We first consider the homogeneous case.
\begin{theorem}
Consider the homogeneous linear equation
\begin{equation*}\tag{$\ast$}
\dv[2]{y}{x}+q\dv{y}{x}+ry=0,
\end{equation*}
where $q,r\in\RR$. The auxilliary equation
\[m^2+qm+r=0\]
has two roots $m_1$ and $m_2$.
\begin{enumerate}[label=(\roman*)]
\item If $m_1\neq m_2$ are real, then the general solution is
\[y(x)=C_1e^{m_1x}+C_2e^{m_2x}.\]
\item If $m=m_1=m_2$ is a repeated real root, then the general solution is
\[y(x)=(C_1x+C_2)e^{mx}.\]
\item If $m_1=\alpha+i\beta$ is a complex root, so that $m_2=\alpha-i\beta$, then the general solution is
\[y(x)=e^{\alpha x}\brac{C_1\cos\beta x+C_2\sin\beta x}.\]
\end{enumerate}
In each case, $C_1$ and $C_2$ are constants.
\end{theorem}

\begin{proof} \
\begin{enumerate}[label=(\roman*)]
\item By Vieta's formula, $m_1+m_2=-q$ and $m_1m_2=r$. Hence ($\ast$) can be written as
\[\dv[2]{y}{x}-(m_1+m_2)\dv{y}{x}+m_1m_2y=0.\]
Note also that $e^{m_1x}$ is a solution of the above equation, so $e^{m_1x}$ is a solution of ($\ast$).

Make the substitution $y(x)=u(x)e^{m_1x}$, then
\[\brac{\dv[2]{u}{x}+2m_1\dv{u}{x}+m_1^2u}-(m_1+m_2)\brac{\dv{u}{x}+m_1u}+m_1m_2u=0,\]
so that
\begin{equation*}\tag{1}
\dv[2]{u}{x}-(m_2-m_1)\dv{u}{x}=0.
\end{equation*}
If $m_2-m_1\neq0$, (1) is in separable form, so the general solution is
\[\dv{u}{x}=ke^{(m_2-m_1)x},\]
so
\[u(x)=C_2e^{(m_2-m_1)x}+C_1.\]
Since $y(x)=u(x)e^{m_1x}$, the desired result follows.

\item If $m_2-m_1=0$ then (1) becomes
\[\dv[2]{y}{x}=0.\]
Integrating directly twice gives
\[u(x)=C_1x+C_2.\]
Since $y(x)=u(x)e^{mx}$, the desired result follows.

\item Suppose now that the roots of the auxiliary equation are conjugate complex numbers $\alpha\pm i\beta$. A simple proof which relies on complex number theory uses Euler's identity
\[e^{i\theta}=\cos\theta+i\sin\theta\]
as follows. Allow $C_1$ and $C_2$ in (i) to be complex numbers; then the required general solution takes the form
\[y(x)=C_1e^{(\alpha+i\beta)x}+C_2e^{(\alpha-i\beta)x}=e^{\alpha x}\brac{\tilde{C_1}\cos\beta x+\tilde{C_2}\sin\beta x},\]
where $\tilde{C_1}$ and $\tilde{C_2}$ are constants, forced to be real if we let $C_2$ be the complex conjugate of $C_1$. These can be renamed as $C_1$ and $C_2$, respectively, to complete the proof.
\end{enumerate}
\end{proof}

We now turn to the inhomogeneous case. We solve these ODEs by applying \cref{thrm:linear-inhomogeneous-ode}; the particular solution $y_p(x)$ is usually found by a mixture of educated guesswork combined with trial and error; the first step is to mimic the form of $f(x)$.