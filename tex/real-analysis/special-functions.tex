\chapter{Some Special Functions}\label{chap:special-functions}
\section{Power Series}
\begin{definition}[Analytic function]
An \vocab{analytic function}\index{analytic function} is a function that can be represented by a power series, i.e., functions of the form
\[f(x)=\sum_{n=0}^\infty c_n x^n\]
or, more generally,
\[f(x)=\sum_{n=0}^\infty c_n(x-a)^n.\]
\end{definition}

As a matter of convenience, we shall often take $a=0$ without any loss of generality.

We shall restrict ourselves to real values of $x$. The \vocab{radius of convergence} is the maximum $R$ such that $f(x)$ converges in $(-R,R)$. If $f(x)$ converges for all $x\in(-R,R)$, for some $R>0$, we say that $f$ is expanded in a power series about the point $x=0$.

\begin{proposition}
Suppose the series $\displaystyle\sum_{n=0}^\infty c_nx^n$ converges for $x\in(-R,R)$. Then
\begin{enumerate}[label=(\roman*)]
\item $\displaystyle\sum_{n=0}^\infty c_nx^n$ converges uniformly on $[-R+\epsilon,R-\epsilon]$ for all $\epsilon>0$;
\item $f(x)$ is continuous and differentiable on $(-R,R)$, and 
\[f^\prime(x)=\sum_{n=1}^\infty nc_nx^{n-1}.\]
\end{enumerate}
\end{proposition}

\begin{proof} \
\begin{enumerate}[label=(\roman*)]
\item Let $\epsilon>0$ be given. For $|x|\le R-\epsilon$, we have
\[|c_nx^n|\le|c_n(R-\epsilon)^n|\]
and since
\[\sum c_n(R-\epsilon)^n\]
converges absolutely (every power series converges absolutely in the interior of its internal of convergence, by the root test), Theorem 7.10 show that $\displaystyle\sum_{n=0}^\infty c_nx^n$ uniformly converges on $[-R+\epsilon,R-\epsilon]$.

\item 
\end{enumerate}
\end{proof}

\begin{corollary}
$f$ has derivatives of all orders in $(-R,R)$, which are given by
\[f^{(k)}(x)=\sum_{n=k}^\infty n(n-1)\cdots(n-k+1)c_nx^{n-k}.\]
In particular,
\[f^{(k)}(0)=k!c_k,\quad k=0,1,2,\dots\]
(Here $f^{(0)}$ means $f$, and $f^{(k)}$ is the $k$-th derivative of $f$, for $k=1,2,3,\dots$)
\end{corollary}

\begin{proof}
Apply theorem successively to $f,f^\prime,f^{\prime\prime},\dots$. Put $x=0$.
\end{proof}

\begin{proposition}
Suppose $\sum c_n$ converges. Put
\[f(x)=\sum_{n=0}^\infty c_n x^n\]
for $x\in(-R,R)$
\end{proposition}

\section{Exponential and Logarithmic Functions}
\begin{definition}[Exponential function]
\begin{equation}
\exp(z)\coloneqq\sum_{n=0}^\infty\frac{z^n}{n!}.
\end{equation}
\end{definition}

\begin{proposition}
$\exp(z)$ converges for every $z\in\CC$.
\end{proposition}

\begin{proof}
Ratio test.
\end{proof}

\begin{proposition}
For $z,w\in\CC$,
\[\exp(z+w)=\exp(z)+\exp(w).\]
\end{proposition}

\begin{corollary}
For $z\in\CC$,
\[\exp(z)\exp(-z)=1.\]
\end{corollary}

\begin{proof}
Take $z=z$, $w=-z$ in the previous result.
\end{proof}

\begin{proposition}
$\exp$ is strictly increasing in $\RR$.
\end{proposition}

\begin{proposition}
For $z\in\CC$,
\[\exp^\prime(z)=\exp(z)\]
\end{proposition}

Further,
\[\exp^\prime(z)=\lim_{h\to0}\frac{\exp(z+h)-\exp(z)}{h}=\lim_{h\to0}\frac{\exp(z+h)-1}{h}\exp(z).\]
Let $\exp(1)=e$. So $\exp(n)=\exp(1+\cdots+1)=\exp(1)\cdots\exp(1)=e^n$. This holds for any $n\in\QQ$.

\section{Trigonometric Functions}
Define
\begin{align*}
C(x)&=\frac{\exp(ix)+\exp(-ix)}{2}\\
S(x)&=\frac{\exp(ix)-\exp(-ix)}{2i}
\end{align*}

Our goal here is to show that $C(x)$ and $S(x)$ coincide with the functions $\cos x$ and $\sin x$, whose definition is usually based on geometric considerations.

\begin{proposition}[Euler's identity]
\[\exp(ix)=C(x)+iS(x).\]
\end{proposition}

\begin{proof}

\end{proof}

From definition, it is easy to see that $C(0)=1$, $S(0)=0$, and
\begin{align*}
C^\prime(x)&=S(x)\\
S^\prime(x)&=C(x)
\end{align*}

\begin{proposition} \
\begin{enumerate}[label=(\roman*)]
\item $\exp$ is periodic, with period $2\pi i$.
\item $C$ and $S$ are periodic, with period $2\pi$.
\item If $0<t<2\pi$, then $\exp(it)\neq1$.
\item If $z\in\CC$, $|z|=1$, there exists a unique $t\in[0,2\pi)$ such that $\exp(it)=z$.
\end{enumerate}
\end{proposition}



\section{Algebraic Completeness of the Complex Field}
We now prove that the complex field is \emph{algebraically complete}; that is, every non-constant polynomial with complex coefficients has a complex root.

\begin{theorem}[Fundamental Theorem of Algebra]
Suppose $a_0,\dots,a_n$ are complex numbers, $n\ge1$, $a_n\neq0$,
\[P(z)=\sum_{k=0}^n a_kz^k.\]
Then $P(z)=0$ for some complex number $z$.
\end{theorem}

\begin{proof}
Without loss of generality, assume $a_n=1$. Let $\mu=\inf|P(z)|$.
\end{proof}

\section{Fourier Series}
\begin{definition}[Trigonometric polynomial]
A \vocab{trigonometric polynomial}\index{trigonometric polynomial} is a finite sum of the form
\[f(x)=a_0+\sum_{n=1}^\infty(a_n\cos nx+b_n\sin nx)\quad(x\in\RR)\]
where $a_0,\dots,a_N,b_1,\dots,b_N\in\CC$.
\end{definition}

We can write the above in the form
\[f(x)=\sum_{n=-N}^N c_ne^{inx}.\]
It is clear that every trigonometric polynomial is periodic, with period $2\pi$.

For non-zero integer $n$, $e^{inx}$ is the derivative of $\frac{1}{in}e^{inx}$, which also has period $2\pi$. Hence
\[\frac{1}{2\pi}\int_{-\pi}^{\pi}e^{inx}\dd{x}=\begin{cases}
1&(n=0)\\
0&(n=\pm1,\pm2,\dots)
\end{cases}\]

\begin{definition}[Fourier coefficients]
If $f$ is an integrable function on $[-\pi,\pi]$, the numbers $c_m$ defined by
\[c_m=\frac{1}{2\pi}\int_{-\pi}^{\pi}f(x)e^{inx}\dd{x}\]
for all integers $m$ are called the \vocab{Fourier coefficients}\index{Fourier coefficients} of $f$.
\end{definition}

\begin{definition}[Fourier series]
The series
\[\sum_{n=-\infty}^{\infty}c_ne^{inx}\]
formed with the Fourier coefficients is called the \vocab{Fourier series}\index{Fourier series} of $f$.
\end{definition}

\begin{definition}[Orthogonal system of functions]
Let $(\phi_n)$ be a sequence of complex functionns on $[a,b]$ such that
\[\int_{a}^{b}\phi_n(x)\overline{\phi_m(x)}\dd{x}=0\quad(n\neq m)\]
Then $(\phi_n)$ is said to be an \vocab{orthogonal system of functions}\index{orthogonal system of functions} on $[a,b]$. If in addition
\[\int_{a}^{b}\absolute{\phi_b(x)}^2\dd{x}=1\]
for all $n$, $(\phi_n)$ is said to be \vocab{orthonormal}.
\end{definition}

\section{Gamma Function}
\begin{definition}[Gamma function]
For $0<x<\infty$, the \vocab{Gamma function}\index{Gamma function} is defined as
\begin{equation}
\Gamma(x)\coloneqq\int_0^\infty t^{x-1}e^{-t}\dd{t}.
\end{equation}
The integral converges for these $x$. (When $x<1$, both $0$ and $\infty$ have to be looked at.)
\end{definition}

\begin{lemma} \
\begin{enumerate}[label=(\roman*)]
\item The functional equation
\[\Gamma(x+1)=x\Gamma(x)\]
holds for $0<x<\infty$.
\item $\Gamma(n+1)=n!$ for $n=1,2,3,\dots$
\item $\log\Gamma$ is convex on $(0,\infty)$.
\end{enumerate}
\end{lemma}

\begin{proof} \
\begin{enumerate}[label=(\roman*)]
\item Integrate by parts.
\item Since $\Gamma(1)=1$, (1) implies (2) by induction.
\item 
\end{enumerate}
\end{proof}

In fact, these three properties characterise $\Gamma$ completely.

\begin{lemma}[Characteristic properties of $\Gamma$] \label{lemma:gamma-char}
If $f$ is a positive function on $(0,\infty)$ such that
\begin{enumerate}[label=(\roman*)]
\item $f(x+1)=xf(x)$,
\item $f(1)=1$,
\item $\log f$ is convex,
\end{enumerate}
then $f(x)=\Gamma(x)$.
\end{lemma}

\begin{proof}

\end{proof}

\begin{definition}[Beta function]
For $x>0$ and $y>0$, the \vocab{beta function}\index{beta functions} is defined as
\[B(x,y)\coloneqq\int_0^1 t^{x-1}(1-t)^{y-1}\dd{t}.\]
\end{definition}

\begin{lemma}
\[B(x,y)=\frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}.\]
\end{lemma}

\begin{proof}
Let $f(x)=\dfrac{\Gamma(x+y)}{\Gamma(y)}B(x,y)$. We want to prove that $f(x)=\Gamma(x)$, using \cref{lemma:gamma-char}.
\begin{enumerate}[label=(\roman*)]
\item \[B(x+1,y)=\int_0^1 t^x(1-t)^{y-1}\dd{t}.\]
Integrating by parts gives
\begin{align*}
B(x+1,y)&=\underbrace{\sqbrac{t^x\cdot\frac{(1-t)^y}{y}(-1)}_0^1}_{0}+\int_0^1 xt^{x-1}\frac{(1-t)^y}{y}\dd{t}\\
&=\frac{x}{y}\int_0^1 t^{x-1}(1-t)^{y-1}(1-t)\dd{t}\\
&=\frac{x}{y}\brac{\int_0^1 t^{x-1}(1-t)^{y-1}\dd{t}-\int_0^1 t^x(1-t)^{y-1}\dd{t}}\\
&=\frac{x}{y}\brac{B(x,y)-B(x+1,y)}
\end{align*}
which gives $B(x+1,y)=\dfrac{x}{x+y}B(x,y)$. Thus
\begin{align*}
f(x+1)&=\frac{\Gamma(x+1+y)}{\Gamma(y)}B(x+1,y)\\
&=\frac{(x+y)B(x+y)}{\Gamma(y)}\cdot\frac{x}{x+y}B(x,y)\\
&=xf(x).
\end{align*}
\item \[B(1,y)=\int_0^1(1-t)^{y-1}\dd{t}=\sqbrac{-\frac{(1-t)^y}{y}}_0^1=\frac{1}{y}\]
and thus
\[f(1)=\frac{\Gamma(1+y)}{\Gamma(y)}B(1,y)=\frac{y\Gamma(y)}{\Gamma(y)}\frac{1}{y}=1.\]
\item We now show that $\log B(x,y)$ is convex, so that
\[\log f(x)=\underbrace{\log\Gamma(x+y)}_\text{convex}+\log B(x,y)-\underbrace{\log\Gamma(y)}_\text{constant}\]
is convex with respect to $x$.
\[B(x_1,y)^\frac{1}{p}B(x_2,y)^\frac{1}{q}=\brac{\int_0^1 t^{x_1-1}(1-t)^{y-1}\dd{t}}^\frac{1}{p}\brac{\int_0^1 t^{x_2-1}(1-t)^{y-1}\dd{t}}^\frac{1}{q}\]
By H\"{o}lder's inequality,
\begin{align*}
B(x_1,y)^\frac{1}{p}B(x_2,y)^\frac{1}{q}
&=\int_0^1\sqbrac{t^{x_1-1}(1-t)^{y-1}}^\frac{1}{p}\sqbrac{t^{x_2-1}(1-t)^{y-1}}^\frac{1}{q}\dd{t}\\
&=\int_0^1 t^{\frac{x_1}{p}+\frac{x_2}{q}-1}(1-t)^{y-1}\dd{t}\\
&=B\brac{\frac{x_1}{p}+\frac{x_2}{q},y}.
\end{align*}
Taking log on both sides gives
\[\log B(x,y)^\frac{1}{p}B(x_2,y)^\frac{1}{q}\ge\log B\brac{\frac{x_1}{p}+\frac{x_2}{q},y}\]
or
\[\frac{1}{p}\log B(x,y)+\frac{1}{q}\log B(x_2,y)\ge\log B\brac{\frac{x_1}{p}+\frac{x_2}{q},y}.\]
Hence $\log B(x,y)$ is convex, so $\log f(x)$ is convex.
\end{enumerate}
Therefore $f(x)=\Gamma(x)$ which implies $B(x,y)=\dfrac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}$.
\end{proof}

An alternative form of $\Gamma$ is as follows:
\[\Gamma(x)=2\int_0^{+\infty}t^{2x-1}e^{-t^2}\dd{t}.\]
Using this form of $\Gamma$, we present an alternative proof.

\begin{proof}
\begin{align*}
\Gamma(x)\Gamma(y)
&=\brac{2\int_0^{+\infty}t^{2x-1}e^{-t^2}\dd{t}}\brac{2\int_0^{+\infty}s^{2y-1}e^{-s^2}\dd{s}}\\
&=4\iint_{[0,+\infty)\times[0,+\infty)}t^{2x-1}s^{2y-1}e^{-\brac{t^2+s^2}}\dd{t}\dd{s}
\end{align*}
Using polar coordinates transformation, let $t=r\cos\theta$, $s=r\sin\theta$. Then $\dd{t}\dd{s}=r\dd{r}\dd{\theta}$. Thus
\begin{align*}
\Gamma(x)\Gamma(y)
&=4\int_0^\frac{\pi}{2}\sqbrac{\int_0^{+\infty}r^{2x-1}\cos^{2x-1}\theta\cdot r^{2y-1}\sin^{2y-1}\theta\cdot e^{-r^2}\cdot r\dd{r}}\dd{\theta}\\
&=\underbrace{2\int_0^\frac{\pi}{2}\cos^{2x-1}\theta\sin^{2y-1}\theta\dd{\theta}}_{B(x,y)}\cdot\underbrace{2\int_0^{+\infty}r^{2(x+y)-1}e^{-r^2}\dd{r}}_{\Gamma(x+y)}
\end{align*}
since
\begin{align*}
B(x,y)&=\int_0^1 t^{x-1}(1-t)^{y-1}\dd{t}\quad t=\cos^2\theta\\
&=\int_\frac{\pi}{2}^0 \cos^{2(x-1)}\theta\sin^{2(y-1)}\theta\cdot2\cos\theta(-\sin\theta)\dd{\theta}\\
&=2\int_0^\frac{\pi}{2}\cos^{2x-1}\theta\sin^{2y-1}\theta\dd{\theta}.
\end{align*}
Hence $B(x,y)=\dfrac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}$.
\end{proof}

More on polar coordinates:
\begin{equation}
I=\int_{-\infty}^{+\infty}e^{-x^2}\dd{x}
\end{equation}

\begin{proof}
\begin{align*}
I^2&=\int_{-\infty}^{+\infty}e^{-x^2}\dd{x}\int_{-\infty}^{+\infty}e^{-y^2}\dd{y}\\
&=\iint_{\RR^2}e^{-\brac{x^2+y^2}}\dd{x}\dd{y}\quad x=r\cos\theta,y=r\sin\theta\\
&=\int_0^{2\pi}\underbrace{\int_0^{+\infty}e^{-r^2}r\dd{r}}_\text{constant w.r.t. $\theta$}\dd{\theta}\quad s=r^2,\dd{s}=2r\dd{r}\\
&=2\pi\int_0^{+\infty}e^{-s}\cdot\frac{1}{2}\dd{s}\\
&=2\pi\sqbrac{\frac{1}{2}e^{-s}(-1)}_0^\infty=\pi
\end{align*}
and thus
\[I=\int_{-\infty}^{+\infty}e^{-x^2}\dd{x}=\sqrt{\pi}.\]
\end{proof}

From this, we have
\[\Gamma\brac{\frac{1}{2}}=2\int_0^\infty e^{-t^2}\dd{t=\sqrt{\pi}.}\]

\begin{lemma}
\[\Gamma(x)=\frac{2^{x-1}}{\sqrt{\pi}}\Gamma\brac{\frac{x}{2}}\Gamma\brac{\frac{x+1}{2}}.\]
\end{lemma}

\begin{proof}
Let $\displaystyle f(x)=\frac{2^{x-1}}{\sqrt{\pi}}\Gamma\brac{\frac{x}{2}}\Gamma\brac{\frac{x+1}{2}}$. We want to prove that $f(x)=\Gamma(x)$.
\begin{enumerate}[label=(\roman*)]
\item \begin{align*}
f(x+1)&=\frac{2^x}{\sqrt{\pi}}\Gamma\brac{\frac{x+1}{2}}\Gamma\brac{\frac{x}{2}+1}\\
&=\frac{2^x}{\sqrt{\pi}}\Gamma\brac{\frac{x+1}{2}}\frac{x}{2}\Gamma\brac{\frac{x}{2}}\\
&=xf(x)
\end{align*}
\item $f(1)=\frac{1}{\sqrt{\pi}}\Gamma\brac{\frac{1}{2}}\Gamma(1)=1$ since $\Gamma\brac{\frac{1}{2}}=\sqrt{\pi}$.
\item \[\log f(x)=\underbrace{(x-1)\log2}_\text{linear}+\underbrace{\log\Gamma\brac{\frac{x}{2}}}_\text{convex}+\underbrace{\log\Gamma\brac{\frac{x+1}{2}}}_\text{convex}-\underbrace{\log\sqrt{\pi}}_\text{constant}\]
and hence $\log f(x)$ is convex.
\end{enumerate}
Therefore $f(x)=\Gamma(x)$.
\end{proof}

\begin{theorem}[Stirling's formula]
This provides a simple approximate expression for $\Gamma(x+1)$ when $x$ is large (hence for $n!$ when $n$ is large). The formula is
\begin{equation}
\lim_{x\to\infty}\frac{\Gamma(x+1)}{(x/e)^x\sqrt{2\pi x}}=1.
\end{equation}
\end{theorem}

\begin{proof}

\end{proof}

\begin{lemma}
\[B(p,1-p)=\Gamma(p)\Gamma(1-p)=\frac{\pi}{\sin p\pi}.\]
\end{lemma}

\begin{proof}

\end{proof}