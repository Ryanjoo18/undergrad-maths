\chapter{Differentiation}\label{chap:differentiation}
\section{The Derivative of A Real Function}
\begin{definition}[Derivative]
Suppose $f:[a,b]\to\RR$. For any $x\in[a,b]$, if the limit
\[\lim_{t\to x}\frac{f(t)-f(x)}{t-x}\quad(a<t<b,t\neq x)\]
exists, we call it $f^\prime$, known as the \vocab{derivative} of $f$.

If $f^\prime$ is defined at a point $x$, we say that $f$ is \vocab{differentiable} at $x$; If $f^\prime$ is defined at every point of a set $E\subseteq[a,b]$, we say that $f$ is differentiable on $E$.
\end{definition}

\begin{lemma}[Differentiability implies continuity]\label{lemma:diff-cont}
If $f:[a,b]\to\RR$ is differentiable at $x\in[a,b]$, then $f$ is continuous at $x$.
\end{lemma}

\begin{proof}
\begin{align*}
\lim_{t\to x}[f(t)-f(x)]
&=\lim_{t\to x}\sqbrac{\frac{f(t)-f(x)}{t-x}\cdot(t-x)}\\
&=\lim_{t\to x}\frac{f(t)-f(x)}{t-x}\cdot\lim_{t\to x}(t-x)\\
&=f^\prime(x)\cdot0=0.
\end{align*}
Since $\displaystyle\lim_{t\to x}f(t)=f(x)$, $f$ is continuous at $x$.
\end{proof}

\begin{remark}
The converse of \cref{lemma:diff-cont} is not true; it is easy to construct continuous functions which fail to be differentiable at isolated points.
\end{remark}

\begin{example}[Weierstrass function]
Let $0<a<1$, let $b>1$ be an odd integer, and $ab>1+\frac{3}{2}\pi$. Then the function
\[W(x)=\sum_{n=0}^{\infty}a^n\cos(b^n\pi x)\]
is continuous and nowhere differentiable on $\RR$.
\end{example}

\begin{notation}
If $f$ has a derivative $f^\prime$ on an interval, and if $f^\prime$ is itself differentiable, we denote the derivative of $f^\prime$ by $f^{\prime\prime}$, and call $f^{\prime\prime}$ the \textbf{second derivative} of $f$. Continuing in this manner, we obtain functions
\[f,f^\prime,f^{\prime\prime},f^{(3)},f^{(4)},\dots,f^{(n)},\]
each of which is the derivative of the preceding one. $f^\prime$ is called the $n$-th derivative (or the derivative or order $n$) of $f$.
\end{notation}

\begin{remark}
In order for $f^{(n)}(x)$ to exist at a point $x$, $f^{(n-1)}(t)$ must exist in a neighbourhood of $x$ (or a one-sided neighbourhood, if $x$ is an endpoint of the interval on which $f$ is defined), and $f^{(n-1)}(x)$ must be differentiable at $x$.
\end{remark}

\begin{notation}
$C_1[a,b]$ denotes the set of differentiable functions over $[a,b]$ whose derivative is continuous. More generally, $C_n[a,b]$ denotes the set of functions whose $n$-th derivative is continuous. In particular, $C_0[a,b]$ is the set of continuous functions over $[a,b]$.
\end{notation}

Later on when we talk about properties of differentiation such as the intermediate value theorems, we usually have the following requirement on the function:
\begin{quote}
$f$ is a continuous function on $[a,b]$ which is differentiable in $(a,b)$.
\end{quote}

\begin{lemma}[Differentiation rules]
Suppose $f,g:[a,b]\to\RR$ are differentiable at $x\in[a,b]$. Then
\begin{enumerate}[label=(\roman*)]
\item Scalar multiplication: for $\alpha\in\RR$, $\alpha f$ is differentiable at $x$, and
\[(\alpha f)^\prime(x)=\alpha f^\prime(x).\]
\item Addition: $f\pm g$ is differentiable at $x$, and
\[(f\pm g)^\prime(x)=f^\prime(x)\pm g^\prime(x).\]
\item Product rule: $fg$ is differentiable at $x$, and
\[(fg)^\prime(x)=f^\prime(x)g(x)+f(x)g^\prime(x).\]
\item Quotient rule: $f/g$ (when $g(x)\neq0$) is differentiable at $x$, and
\[\brac{\frac{f}{g}}^\prime(x)=\frac{f^\prime(x)g(x)-f(x)g^\prime(x)}{g(x)^2}.\]
\end{enumerate}
\end{lemma}

\begin{proof} \
\begin{enumerate}[label=(\roman*)]
\item 
\item \begin{align*}
\frac{(f+g)(t)-(f+g)(x)}{t-x}
&=\frac{f(t)+g(t)-f(x)-g(x)}{t-x}\\
&=\frac{f(t)-f(x)}{t-x}+\frac{g(t)-f(x)}{t-x}
\end{align*}
Taking limits $t\to x$, the first term equals to $f^\prime(x)$, and the second term equals to $g^\prime(x)$. The case for subtraction is analogous.

\item \begin{align*}
\frac{(fg)(t)-(fg)(x)}{t-x}
&=\frac{f(t)g(t)-f(x)g(x)}{t-x}\\
&=\frac{\sqbrac{f(t)-f(x)}g(t)+f(x)\sqbrac{g(t)-g(x)}}{t-x}\\
&=\frac{f(t)-f(x)}{t-x}\cdot g(t)+f(x)\cdot\frac{g(t)-g(x)}{t-x}\\
&=f^\prime(x)g(x)+f(x)g^\prime(x)
\end{align*}
Taking limits $t\to x$, the first term equals to $f^\prime(x)g(x)$, and the second term equals to $f(x)g^\prime(x)$, so we are done.

\item Similarly,
\[\frac{\brac{\frac{f}{g}}(t)-\brac{\frac{f}{g}}(x)}{t-x}=\frac{1}{g(t)g(x)}\sqbrac{g(x)\cdot\frac{f(t)-f(x)}{t-x}-f(x)\cdot\frac{g(t)-g(x)}{t-x}}\]
Taking limits $t\to x$, the result immediately follows.
\end{enumerate}
\end{proof}

By induction, we can obtain the following extensions of the differentiation rules.

\begin{corollary}
Suppose $f_1,f_2,\dots,f_n:[a,b]\to\RR$ are differentiable at $x\in[a,b]$. Then
\begin{enumerate}[label=(\roman*)]
\item $f_1+f_2+\cdots+f_n$ is differentiable at $x$, and
\[(f_1+f_2+\cdots+f_n)^\prime(x)={f_1}^\prime(x)+{f_2}^\prime(x)+\cdots+{f_n}^\prime(x).\]
\item $f_1f_2\cdots f_n$ is differentiable at $x$, and
\begin{align*}
(f_1f_2\cdots f_n)^\prime(x)
=&{f_1}^\prime(x)f_2(x)\cdots f_n(x)+f_1(x){f_2}^\prime(x)\cdots f_n(x)\\
&+\cdots+f_1(x)f_2(x)\cdots {f_n}^\prime(x).
\end{align*}
\end{enumerate}
\end{corollary}

\begin{theorem}[Chain rule]
Suppose $f$ is continuous on $[a,b]$, $f^\prime(x)$ exists at $x\in[a,b]$, $g$ is defined on $I$ that contains $f([a,b])$, and $g$ is differentiable at $f(x)$. Then the composition
\[h(x)\coloneqq g\circ f(x)=g\brac{f(x)}:[a,b]\to\RR\]
is differentiable at $x$, and the derivative at $x$ can be calculated as
\[h^\prime(x)=g^\prime\brac{f(x)}f^\prime(x).\]
\end{theorem}

\begin{proof}
Let $y=f(x)$. By the definition of the derivative, we have
\begin{equation*}\tag{1}
f(t)-f(x)=(t-x)[f^\prime(x)+u(t)]
\end{equation*}
\begin{equation*}\tag{2}
g(s)-g(y)=(s-y)[g^\prime(y)+v(s)]
\end{equation*}
where $t\in[a,b]$, $s\in I$, $\lim_{t\to x}u(t)=0$, $\lim_{s\to y}v(s)=0$.

Let $s=f(t)$. Using first (2) and then (1), we obtain
\begin{align*}
h(t)-h(x)
&=g\brac{f(t)}-g\brac{f(x)}\\
&=[f(t)-f(x)]\cdot[g^\prime(y)+v(s)]\\
&=(t-x)[f^\prime(x)+u(t)][g^\prime(y)+v(s)],
\end{align*}
or, if $t\neq x$,
\[\frac{h(t)-h(x)}{t-x}=[g^\prime(y)+v(s)][f^\prime(x)+u(t)].\]
Letting $t\to x$, we see that $s\to y$, by the continuity of $f$, so that the RHS of the above equation tends to $g^\prime(y)f^\prime(x)$, thus giving us the desired result.
\end{proof}

\begin{example}
One family of pathological examples in calculus is functions of the form
\[f(x)=x^p\sin\frac{1}{x}.\]
For $p=1$, the function is continuous and differentiable everywhere other than $x=0$; for $p=2$, the function is differentiable everywhere, but the derivative is discontinuous.
\end{example}

\section{Mean Value Theorems}
Let $(X,d)$ be a metric space.

\begin{definition}[Local maximum and minimum]
We say that $f:X\to\RR$ has
\begin{enumerate}[label=(\roman*)]
\item a \vocab{local maximum} at $x_0\in X$ if there exists $\delta>0$ such that $f(x_0)\ge f(x)$ for all $x\in B_\delta(x_0)$;
\item a \vocab{local minimum} at $x_0\in X$ if there exists $\delta>0$ such that $f(x_0)\le f(x)$ for all $x\in B_\delta(x_0)$.
\end{enumerate}
\end{definition}

\begin{lemma}[Fermat's theorem]
Suppose $f:[a,b]\to\RR$. If $f$ has a local maximum or minimum at $x_0\in(a,b)$, and if $f^\prime(x_0)$ exists, then $f^\prime(x_0)=0$.
\end{lemma}

\begin{proof}
If $f$ is not differentiable at $x_0$, we are done. Assume now $f$ is differentiable at $x_0$ and $x_0$ is a local maximum. By definition, there exists $\delta>0$ such that $f(x_0)\le f(x)$, for all $x\in B_\delta(x_0)$. Then
\[ \frac{f(x)-f(x_0)}{x-x_0}\begin{cases}
\ge0 & x_0-\delta<x<x+\delta\\
\le0 & x_0<x<x_0+\delta
\end{cases} \]
Since $f^\prime(x_0)$ exists, we have
\[ f^\prime(x_0-)\ge0, \quad f^\prime(x_0+)\le0, \]
but we know that $f^\prime(x_0-)=f^\prime(x_0+)=f^\prime(x_0)$ since $f$ is differentiable at $x_0$. Hence $f^\prime(x_0)=0$.
\end{proof}

\begin{theorem}[Rolle's theorem]\label{thrm:rolle}
If $f$ is continuous on $[a,b]$, differentiable in $(a,b)$ and $f(a)=f(b)$, then there exists $c\in(a,b)$ such that 
\[ f^\prime(c)=0. \]
\end{theorem}

\begin{proof}
Let $h(x)$ be a function defined on $[a,b]$ where $h(a)=h(b)$.

The idea is to show that $h$ has a local maximum/minimum, then by Fermat's Theorem this will then be the stationary point that we're trying to find.

First note that $h$ is continuous on $[a,b]$, so $h$ must have a maximum $M$ and a minimum $m$.

If $M$ and $m$ were both equal to $h(a)=h(b)$, then $h$ is just a constant function and so $h^\prime(x)=0$ everywhere.

Otherwise, $h$ has a maximum/minimum that is not $h(a)=h(b)$, so this extremal point lies in $(a,b)$.

In particular, this extremal point is also a local extremum.
Since $h$ is differentiable on $(a,b)$, by Fermat's theorem this extremum point is stationary, thus Rolle's Theorem is proven.
\end{proof}

\begin{theorem}[Generalised mean value theorem]\label{thrm:generalised-mvt}
If $f$ and $g$ are continuous on $[a,b]$ and differentiable in $(a,b)$, then there exists $c\in(a,b)$ such that
\[ \frac{f^\prime(c)}{g^\prime(c)}=\frac{f(b)-f(a)}{g(b)-g(a)}. \]
\end{theorem}

\begin{proof}
For $t\in[a,b]$, put
\[h(t)=[f(b)-f(a)]g(t)-[g(b)-g(a)]f(t).\]
Then $h$ is continuous on $[a,b]$, and $h$ is differentiable on $(a,b)$. Moreover,
\[h(a)=f(b)g(a)-f(a)g(b)=h(b)\]
thus by Rolle's Theorem, there exists $c\in(a,b)$ such that $h^\prime(c)=0$, i.e. $[g(b)-g(a)]f^\prime(c)=[f(b)-f(a)]g^\prime(c)$
\end{proof}

\begin{theorem}[Mean value theorem]\label{thrm:mvt}
If $f$ is continuous on $[a,b]$ and differentiable in $(a,b)$, then there exists $c\in(a,b)$ such that
\[ f^\prime(c)=\frac{f(b)-f(a)}{b-a}. \]
\end{theorem}

\begin{proof}
Take $g(x)=x$ in \cref{thrm:generalised-mvt}.
\end{proof}

\begin{proposition}
Suppose $f$ is differentiable in $(a,b)$.
\begin{enumerate}[label=(\roman*)]
\item If $f^\prime(x)\ge0$ for all $x\in(a,b)$, then $f$ is monotonically increasing.
\item If $f^\prime(x)=0$ for all $x\in(a,b)$, then $f$ is constant.
\item If $f^\prime(x)\le0$ for all $x\in(a,b)$, then $f$ is monotonically decreasing.
\end{enumerate}
\end{proposition}

\begin{proof}
All conclusions can be read off from the equation
\[f^\prime(x)=\frac{f(x_2)-f(x_1)}{x_2-x_1},\]
which is valid, for each pair of numbers $x_1,x_2$ in $(a,b)$, for some $x$ between
$x_1$ and $x_2$.
\end{proof}

\begin{exercise}
Let $f$ and $g$ be continuous on $[a,b]$ and differentiable on $(a,b)$. If $f^\prime(x)=g^\prime(x)$, then $f(x)=g(x)+C$.
\end{exercise}

\begin{exercise}
Given that $f(x)=x^\alpha$ where $0<\alpha<1$. Prove that $f$ is uniformly continuous on $[0,+\infty)$.
\end{exercise}

\begin{exercise}
Let $f$ be a function continuous on $[0,1]$ and differentiable on $(0,1)$ where $f(0)=f(1)=0$. Prove that there exists $c\in(0,1)$ such that
\[ f(x)+f^\prime(x)=0. \]
\end{exercise}

\section{Darboux's Theorem}
The following result implies some sort of a ``intermediate value'' property of derivatives that is similar to continuous functions.

\begin{theorem}[Darboux's Theorem]
Suppose $f$ is differentiable on $[a,b]$, and suppose $f^\prime(a)<c<f^\prime(b)$. Then there exists $x\in(a,b)$ such that $f^\prime(x)=c$.
\end{theorem}

\begin{proof}
Put $g(t)=f(t)-ct$. Then $g^\prime(a)<0$, so that $g(t_1)<g(a)$ for some $t_1\in(a,b)$, and $g^\prime(b)>0$, so that $g(t_2)<g(b)$ for some $t_2\in(a,b)$.

Hence $g$ attains its minimum on $[a,b]$ (Theorem 4.16) at some point $x$ such that $a<x<b$. By Theorem 5.8, $g^\prime(x)=0$. Hence $f^\prime(x)=c$.
\end{proof}

\begin{corollary}
If $f$ is differentiable on $[a,b]$, then $f^\prime$ cannot have any simple discontinuities on $[a,b]$.
\end{corollary}

\begin{remark}
But $f^\prime$ may very well have discontinuities of the second kind.
\end{remark}

\section{L'Hopital's Rule}
The following theorem is frequently used in the evaluation of limits.

\begin{theorem}[L'Hopital's Rule]
Suppose $f$ and $g$ are differentiable over $(a,b)$ with $g^\prime(x)\neq0$ for all $x\in(a,b)$, where $-\infty\le a<b\le+\infty$. If either
\begin{enumerate}[label=(\roman*)]
\item $\displaystyle\lim_{x\to a}f(x)=0$ and $\displaystyle\lim_{x\to a}g(x)=0$; or
\item $\displaystyle\lim_{x\to a}|g(x)|=+\infty$,
\end{enumerate}
and
\[\lim_{x\to a}\frac{f^\prime(x)}{g^\prime(x)}=A,\]
then
\[\lim_{x\to a}\frac{f(x)}{g(x)}=A.\]
\end{theorem}

\begin{proof}
The entire proof is rather tedious because we have to many cases.

We first consider the case in which $-\infty\le A<+\infty$. Choose $q\in\RR$ such that $A<q$, and choose $r\in\RR$ such that $A<r<q$.

1. $\frac{0}{0}$ or $\frac{\infty}{\infty}$
2. a is normal or $a=-\infty$
3. A is normal or $A=\pm\infty$



We'll only prove the most basic one here:
0/0, a and A are normal
This is the case which will be required for Taylor series

First we define f(a)=g(a)=0, so that $f$ and $g$ are continuous at $x=a$

Now let $x\in(a,b)$, then $f$ and $g$ are continuous on $[a,x]$ and differentiable in $(a,x)$
:
Thus by Cauchy's Mean Value Theorem, there exists $\xi\in(a,x)$ such that
\[ \frac{f^\prime(\xi)}{g^\prime(\xi)}=\frac{f(x)-f(a)}{g(x)-g(a)}=\frac{f(x)}{g(x)} \]

For each $x$, we pick $\xi$ which satisfies the above, so that $\xi$ may be seen as a function of $x$ satisfying $a<\xi(x)<x$

Then by squeezing we have $\lim_{x\to a^+}\xi(x)=a$.

Since $\frac{f^\prime}{g^\prime}$ is continuous near $a$, the theorem regarding the limit of composite functions give
\[ \lim_{x\to a^+}\frac{f(x)}{g(x)} = \lim_{x\to a^+}\frac{f'(\xi)}{g'(\xi)} = \lim_{x\to a^+}\brac{\frac{f^\prime}{g^\prime}}(\xi(x)) = A \]

Now the same reasoning can be used for $b$ where we will use lim(xâ†’b-) to replace all the $\lim_{x\to a^+}$, and $\xi$ will be a function which maps to $(x,b)$.
\end{proof}

\section{Taylor Expansion}
\begin{theorem}[Taylor's Theorem]
Suppose $f:[a,b]\to\RR$, $f^{(n-1)}$ is continuous on $[a,b]$, $f^{(n)}(t)$ exists for every $t\in(a,b)$. Let $\alpha$ and $\beta$ be distinct points of $[a,b]$, and define
\[P(t)=\sum_{k=0}^{n-1}\frac{f^{(k)}(\alpha)}{k!}(t-\alpha)^k.\]
Then there exists $x\in[\alpha,\beta]$ such that
\[f(\beta)=P(\beta)+\frac{f^{(n)}(x)}{n!}(\beta-\alpha)^n.\]
\end{theorem}



\begin{comment}
Consider a function $f:[a,b]\to\RR$. We first look at the mean value theorem from the viewpoint of approximations for $f(x)$ near a point $x=a$. We can regard the constant function
\[ f_0(x)=f(a) \]
as the \vocab{zero order approximation} of $f(x)$. Then we ask if we can understand the remainder
\[ R_1(x)\coloneqq f(x)-f(a), \quad x\in[a,b] \]
for this approximation. For this, if we assume $f\in C_0[a,b]$ and $f^\prime$ exists over $(a,b)$, then the mean value theorem tells us that there exists some $a<\xi_x<x$ (here $\xi_x$ vocabasises that $\xi$ depends on $x$) so that we can write $R_1$ as
\[ R_1(x)=f^\prime(\xi_x)(x-a). \]
This is saying that the derivative of $f$ can control the remainder $R_1(x)$ as an order 1 monomial.



%%%%%%%%%%%%%%%%

The main expression is as follows:
\begin{equation}
f(x)=f(a)+\frac{f^\prime(a)}{1!}(x-a)+\frac{f^{\prime\prime}(a)}{2!}(x-a)^2+\frac{f^{\prime\prime\prime}(a)}{3!}(x-a)^3+\cdots
\end{equation}

So for example we have the following (we've used the ones for $e^x$ and $\ln x$ for generating functions):
\begin{align*}
e^x &= 1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+\cdots \\
\sin x &= x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots \\
\cos x &= 1-\frac{x^2}{2!}+\frac{x^4}{4!}-\frac{x^6}{6!}+\cdots \\
\ln(1+x) &= x-\frac{x^2}{2}+\frac{x^3}{3}-\frac{x^4}{4}+\cdots
\end{align*}

There's a lot of things to say about these equations, for example the one for $\ln(1+x)$ only works for $|x|<1$

Also, if you want the RHS of the expression to be an infinite power series, $f(x)$ has to be smooth (infinitely differentiable)

Even then, the power series may never converge to $f(x)$ at any interval, no matter how small
The most common example given here is $f(x)=e^\frac{-1}{x^2}$ (f(0)=0); the Taylor series for $f(x)$ is just $0$

Now sometimes we don't actually that nice of a property for f, we're often given that fact that $f$ is only finitely differentiable

Then we will have something along the lines of
\[ f(x)\approx f(a)+\frac{f^\prime(a)}{1!}(x-a)+\frac{f^{\prime\prime}(a)}{2!}(x-a)^2+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n \]
where $f^{(n)}$ denotes the $n$-th differential.

There are two main forms of the statement regarding the error between the original function and the Taylor series estimate

The simpler form is what's known as the Peano form: Given that f is n times differentiable at $a$, then
\[ f(x)=f(a)+\frac{f^\prime(a)}{1!}(x-a)+\frac{f^{\prime\prime}(a)}{2!}(x-a)^2+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n+o((x-a)^n) \]

To show this, we only need to show that we have the following limit:
\[ \lim_{x\to a}\frac{f(x)-{f(a)+\frac{f^\prime(a)}{1!}(x-a)+\frac{f^{\prime\prime}(a)}{2!}(x-a)^2+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n}}{(x-a)^n}=0 \]

The basic idea is to use the L'Hopital Rule n times. The numerator becomes $f^{(n)}(x)-f^{(n)}(a)$ which approaches $0$, whereas the denominater is just $n!$, so the limit exists and is equal to $0$.

However, we need to verify all the necessary conditions for L'Hopital
:
Here the main problem is that we don't know if we have the 0/0 indeterminate at each step, so we'll need to check this for the k-th step where k=1,...,n

Fortunately, the k-th derivative of the numerator is
$f^{(k)}(x)-f^{(k)}(a)-(x-a)F_k(x)$ where $F_k$ is just a bunch of random stuff, so the numerator approaches $0$ as $x\to a$
The $k$-th derivative of the denominator is $n(n-1)\cdots(n-k+1)(x-a)^{n-k}$ so it also approaches $0$, and we're done

The other form is actually a family of similar statements which gives more precise values for the error
The Peano form has a fundamental obstacle when used in approximation, we don't have any control on the size of the final term other than its asymptotic behaviour
:
We'll be talking about the one given in the book, known as the Lagrange form:
:
Given that f is n times differentiable on $(a,b)$ such that $f^{(n-1)}$ is continuous on $[a,b]$, then
\[ f(x)=f(a)+\frac{f^\prime(a)}{1!}(x-a)+\frac{f^{\prime\prime}(a)}{2!}(x-a)^2+\cdots+\frac{f^{(n-1)}(a)}{(n-1)!}(x-a)^(n-1)+\frac{f^{(n)}(\xi)}{n!}(x-a)^n \]

Just like in L'Hopital, we intuitively think of $(a,b)$ as just a very small interval at the right hand side of x=a
:
Here we are giving up on the second final term of Peano by combining it with the infinitesimal (small o) term to give an accurate description of the error

For the proof of this one we'll be using Cauchy's MVT

Fix any $x\in(a,b)$, then we construct the functions
\[ F(t)=f(x)-\brac{f(t)+\frac{f^\prime(t)}{1!}(x-t)+\frac{f^{\prime\prime}(t)}{2!}(x-t)^2+\cdots+\frac{f^{(n-1)}(t)}{(n-1)!}(x-t)^{n-1}} \]
\[ G(t)=(x-t)^n \]

We calculate $F^\prime(t)$ as follows:
\[ -[f^\prime(t)+\frac{f^{\prime\prime}(t)}{1!}-f^\prime(t)+\frac{f^{\prime\prime\prime}(t)}{2!}-\frac{f^{\prime\prime}(t)}{1!}+\cdots+\frac{f^{(n)}(t)}{(n-1)!}(x-t)^{n-1}-\frac{f^{(n-1)}(t)}{(n-2)!}(x-t)^{n-2}]=-\frac{f^{(n)}(t)}{(n-1)!}(x-t)^{n-1} \]

$G^\prime(t)=-n(x-t)^{n-1}$, so we have
\[ \frac{F^\prime(t)}{G^\prime(t)}=\frac{f^{(n)}(t)}{n!} \]

The main reason for why we come up with the strange-looking $F$ and $G$ is that we specifically swap out $a$ for $t$ so that $F(x)=G(x)=0$, in hopes of getting rid of $x$:

We apply Cauchy's MVT to $F$ and $G$ on $[a,x]$, so that we obtain $\xi\in(a,x)$ satisfying
\[ \frac{F^\prime(\xi)}{G^\prime(\xi)}=\frac{F(x)-F(a)}{G(x)-G(a)}=\frac{F(a)}{G(a)}. \]
Thus the Lagrange form of the remainder is given by 
\[ F(a)=\frac{f^{(n)}(\xi)}{n!}G(a). \]
\end{comment}
